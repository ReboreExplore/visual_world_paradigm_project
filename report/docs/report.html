<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Pritom Gogoi, Manpa Barman, Kapil Chander Mulchandani">
<meta name="dcterms.date" content="2023-08-29">

<title>Visual World Paradigm</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="report_files/libs/clipboard/clipboard.min.js"></script>
<script src="report_files/libs/quarto-html/quarto.js"></script>
<script src="report_files/libs/quarto-html/popper.min.js"></script>
<script src="report_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="report_files/libs/quarto-html/anchor.min.js"></script>
<link href="report_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="report_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="report_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="report_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="report_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-full">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#visual-world-paradigm" id="toc-visual-world-paradigm" class="nav-link" data-scroll-target="#visual-world-paradigm"><span class="header-section-number">1.1</span> Visual World Paradigm</a></li>
  <li><a href="#objective-of-our-project" id="toc-objective-of-our-project" class="nav-link" data-scroll-target="#objective-of-our-project"><span class="header-section-number">1.2</span> Objective of our project</a></li>
  </ul></li>
  <li><a href="#experiment" id="toc-experiment" class="nav-link" data-scroll-target="#experiment"><span class="header-section-number">2</span> Experiment</a>
  <ul class="collapse">
  <li><a href="#software-and-hardware" id="toc-software-and-hardware" class="nav-link" data-scroll-target="#software-and-hardware"><span class="header-section-number">2.1</span> Software and Hardware</a></li>
  <li><a href="#structure-of-the-stimulus" id="toc-structure-of-the-stimulus" class="nav-link" data-scroll-target="#structure-of-the-stimulus"><span class="header-section-number">2.2</span> Structure of the Stimulus</a></li>
  <li><a href="#design-of-the-experiment" id="toc-design-of-the-experiment" class="nav-link" data-scroll-target="#design-of-the-experiment"><span class="header-section-number">2.3</span> Design of the Experiment</a></li>
  <li><a href="#logic-of-the-experiment" id="toc-logic-of-the-experiment" class="nav-link" data-scroll-target="#logic-of-the-experiment"><span class="header-section-number">2.4</span> Logic of the experiment</a></li>
  </ul></li>
  <li><a href="#stimulus-design" id="toc-stimulus-design" class="nav-link" data-scroll-target="#stimulus-design"><span class="header-section-number">3</span> Stimulus Design</a></li>
  <li><a href="#stimuli-preprocessing" id="toc-stimuli-preprocessing" class="nav-link" data-scroll-target="#stimuli-preprocessing"><span class="header-section-number">4</span> Stimuli Preprocessing</a></li>
  <li><a href="#conditions" id="toc-conditions" class="nav-link" data-scroll-target="#conditions"><span class="header-section-number">5</span> Conditions</a></li>
  <li><a href="#randomization-and-quality-control" id="toc-randomization-and-quality-control" class="nav-link" data-scroll-target="#randomization-and-quality-control"><span class="header-section-number">6</span> Randomization and Quality Control</a></li>
  <li><a href="#experiment-organization" id="toc-experiment-organization" class="nav-link" data-scroll-target="#experiment-organization"><span class="header-section-number">7</span> Experiment Organization</a></li>
  <li><a href="#preprocessing-and-analysis" id="toc-preprocessing-and-analysis" class="nav-link" data-scroll-target="#preprocessing-and-analysis"><span class="header-section-number">8</span> Preprocessing and Analysis</a>
  <ul class="collapse">
  <li><a href="#organizing-the-raw-data-into-trial-wise-data" id="toc-organizing-the-raw-data-into-trial-wise-data" class="nav-link" data-scroll-target="#organizing-the-raw-data-into-trial-wise-data"><span class="header-section-number">8.1</span> Organizing the raw data into trial-wise data</a></li>
  <li><a href="#extracting-trial-information" id="toc-extracting-trial-information" class="nav-link" data-scroll-target="#extracting-trial-information"><span class="header-section-number">8.2</span> Extracting trial information</a></li>
  <li><a href="#fixation-plots" id="toc-fixation-plots" class="nav-link" data-scroll-target="#fixation-plots"><span class="header-section-number">8.3</span> Fixation plots</a></li>
  <li><a href="#deduce-location-of-fixations" id="toc-deduce-location-of-fixations" class="nav-link" data-scroll-target="#deduce-location-of-fixations"><span class="header-section-number">8.4</span> Deduce location of fixations</a></li>
  <li><a href="#mapping-stimulus-location-to-stimulus-type" id="toc-mapping-stimulus-location-to-stimulus-type" class="nav-link" data-scroll-target="#mapping-stimulus-location-to-stimulus-type"><span class="header-section-number">8.5</span> Mapping stimulus location to stimulus type</a></li>
  <li><a href="#issue-of-unequal-entries-per-trial" id="toc-issue-of-unequal-entries-per-trial" class="nav-link" data-scroll-target="#issue-of-unequal-entries-per-trial"><span class="header-section-number">8.6</span> Issue of unequal entries per trial</a>
  <ul class="collapse">
  <li><a href="#plotting-the-number-of-fixations-per-trial-for-one-participant" id="toc-plotting-the-number-of-fixations-per-trial-for-one-participant" class="nav-link" data-scroll-target="#plotting-the-number-of-fixations-per-trial-for-one-participant"><span class="header-section-number">8.6.1</span> Plotting the number of fixations per trial for one participant</a></li>
  <li><a href="#comparing-the-trial-durations-for-each-condition-number" id="toc-comparing-the-trial-durations-for-each-condition-number" class="nav-link" data-scroll-target="#comparing-the-trial-durations-for-each-condition-number"><span class="header-section-number">8.6.2</span> Comparing the trial durations for each condition number</a></li>
  <li><a href="#solution-binning-the-data" id="toc-solution-binning-the-data" class="nav-link" data-scroll-target="#solution-binning-the-data"><span class="header-section-number">8.6.3</span> Solution: Binning the data</a></li>
  </ul></li>
  <li><a href="#implementing-the-conditions-of-competitor-sets" id="toc-implementing-the-conditions-of-competitor-sets" class="nav-link" data-scroll-target="#implementing-the-conditions-of-competitor-sets"><span class="header-section-number">8.7</span> Implementing the conditions of competitor sets</a></li>
  <li><a href="#prepare-data-for-plotting" id="toc-prepare-data-for-plotting" class="nav-link" data-scroll-target="#prepare-data-for-plotting"><span class="header-section-number">8.8</span> Prepare data for plotting</a>
  <ul class="collapse">
  <li><a href="#one-hot-encoding" id="toc-one-hot-encoding" class="nav-link" data-scroll-target="#one-hot-encoding"><span class="header-section-number">8.8.1</span> One hot encoding</a></li>
  <li><a href="#implementing-the-conditions-of-the-analysis-plot" id="toc-implementing-the-conditions-of-the-analysis-plot" class="nav-link" data-scroll-target="#implementing-the-conditions-of-the-analysis-plot"><span class="header-section-number">8.8.2</span> Implementing the conditions of the analysis plot</a></li>
  </ul></li>
  <li><a href="#calculating-the-fixation-probabilities" id="toc-calculating-the-fixation-probabilities" class="nav-link" data-scroll-target="#calculating-the-fixation-probabilities"><span class="header-section-number">8.9</span> Calculating the fixation probabilities</a></li>
  <li><a href="#saving-per-participant-data" id="toc-saving-per-participant-data" class="nav-link" data-scroll-target="#saving-per-participant-data"><span class="header-section-number">8.10</span> Saving per participant data</a></li>
  <li><a href="#plot-of-the-final-analysis" id="toc-plot-of-the-final-analysis" class="nav-link" data-scroll-target="#plot-of-the-final-analysis"><span class="header-section-number">8.11</span> Plot of the final analysis</a></li>
  <li><a href="#analysis-of-the-obtained-results" id="toc-analysis-of-the-obtained-results" class="nav-link" data-scroll-target="#analysis-of-the-obtained-results"><span class="header-section-number">8.12</span> Analysis of the obtained results</a></li>
  </ul></li>
  <li><a href="#challenges-and-limitations" id="toc-challenges-and-limitations" class="nav-link" data-scroll-target="#challenges-and-limitations"><span class="header-section-number">9</span> Challenges and Limitations</a>
  <ul class="collapse">
  <li><a href="#what-we-did-not-replicate-from-the-reference-paper" id="toc-what-we-did-not-replicate-from-the-reference-paper" class="nav-link" data-scroll-target="#what-we-did-not-replicate-from-the-reference-paper"><span class="header-section-number">9.1</span> What we did not replicate from the reference paper?</a></li>
  <li><a href="#challenges" id="toc-challenges" class="nav-link" data-scroll-target="#challenges"><span class="header-section-number">9.2</span> Challenges</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations"><span class="header-section-number">9.3</span> Limitations</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">10</span> Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="report.pdf"><i class="bi bi-file-pdf"></i>PDF (titlepage)</a></li></ul></div></nav>
</div>
<main class="content column-page-left" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><strong>Visual World Paradigm</strong></h1>
<p class="subtitle lead">A classical visual world study showing how people predict upcoming words with the help of Gazepoint eye tracker</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Pritom Gogoi, Manpa Barman, Kapil Chander Mulchandani </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <a href="https://www.uni-stuttgart.de/en/">
            University of Stuttgart
            </a>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">August 29, 2023</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    The study presented in this paper explores the dynamics of predictive language processing through the visual world paradigm (VWP), a widely employed method in cognitive psychology. The primary objective of the research is to unwind how individuals anticipate or predict forthcoming words during the unfolding of the spoken instructions, leveraging the Gazepoint eye tracker for precise gaze pattern analysis. The investigation delves into the impact of competitor words on gaze patterns, to study the cognitive mechanisms underlying real-time language comprehension. Our experiment uses a collection of competitor words sharing phonetic or semantic similarities with the target, and validates the hypothesis that the existence of such competitors leads to an increased number of fixations on them, reflecting the participants’ evolving predictions of the upcoming word.
  </div>
</div>

</header>

<p><a href="https://github.com/ReboreExplore/visual_world_paradigm_project/blob/main/report/docs/report.pdf">Download the PDF version</a></p>
<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<section id="visual-world-paradigm" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="visual-world-paradigm"><span class="header-section-number">1.1</span> Visual World Paradigm</h2>
<p>The visual world paradigm is an experimental framework that investigates language processing by monitoring participants’ eye movements while they interact with visual stimuli. Introduced by psychologists Richard Cooper and Thomas P. McDermott in the late 1990s, this paradigm have been continuosly refined and expanded, adapting it to different research questions and using advancements in eye-tracking technology to gain deeper insights into real-time language comprehension and visual attention processes. Through this framework the researchers try to simulate the integration of spoken language and visual information as they naturally occur in everyday situations so that we can draw inferences on the attention focus on specific objects in their visual display over time.</p>
</section>
<section id="objective-of-our-project" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="objective-of-our-project"><span class="header-section-number">1.2</span> Objective of our project</h2>
<p>Our research question is:</p>
<p></p>
<p>Our project is to study the nature of spoken word recognition as the word unfolds. We try to investigate the visual world paradigm by using the participants’ eye movements which serve as an index of their ongoing language processing and interpretation. We dive deeper in trying to understand how the participants predict the upcoming word in a spoken instruction and how the cognitive mechanisms underlying real-time language comprehension influence their gaze patterns.</p>
<p>We aim to explore two fundamental conclusions concerning spoken word recognition and the underlying models, based upon the established research in this domain:</p>
<ul>
<li>Spoken word recognition is dynamic in nature which suggests that listeners continuously update and refine their interpretations as more information becomes available. It is not a discrete process rather it is a continuous process that unfolds over time.</li>
<li>Spoken word recognition models make assumptions that multiple candidates compete for recognition during the unfolding of the spoken word.</li>
</ul>
<p>Paul D.Allopenna, James S. Magnuson and Michael K. Tanenhaus in their paper investigated a similar structure of the experiment and found the following results:</p>
<div id="fig-matrix" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/ref_graph.png" class="img-fluid figure-img" style="width:90.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Probability of fixating on each item type over time in the full competitor condition</figcaption>
</figure>
</div>
<p>In this figure we have the probability of fixation on four words:</p>
<ol type="1">
<li>Referent (e.g., beaker): Target Word</li>
<li>Cohort (e.g., beetle): Similar Sounding Word</li>
<li>Rhyme (e.g., speaker): Rhyming word</li>
<li>Unrelated (e.g., carriage): Unrelated word to the rest (phonetically or semantically.)</li>
</ol>
<p>In the beginning the participants hear [bi], which could be the beginning of <em>beaker</em> but also could be the beginning of <em>beetle</em>. So during the first 400 ms the particpants start looking at both of those words, more than they look at the others. After some time as they hear the [k] i.e.&nbsp;now they are hearing [bik], thus they discard their choice of <em>beetle</em> and stop looking at it. But by the time they’ve heard the whole word <em>beaker</em>, they might realize that <em>beaker</em> rhymes almost exactly with <em>speaker</em> and get confused about if they heard <em>speaker</em> at the very first place. For the last word carriage the pronunciation is totally unrelated to the target <em>beaker</em>, so there is a very less probability of the participant actually fixation at the unrelated word.</p>
<p>Through we try to replicate the results obtained by Paul D.Allopenna, James S. Magnuson and Michael K. Tanenhaus in their paper and validate their hypothesis.</p>
</section>
</section>
<section id="experiment" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Experiment</h1>
<section id="software-and-hardware" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="software-and-hardware"><span class="header-section-number">2.1</span> Software and Hardware</h2>
<ul>
<li><p><strong>Software</strong>: The experiment is designed in <a href="https://osdoc.cogsci.nl/">OpenSesame</a> which is a open source software to create experiments for psychology, neuroscience, and experimental economics.</p></li>
<li><p><strong>Language</strong>: Python was used along with the OpenSesame GUI to create the experiment. Libraries like Pandas, Numpy, Matplotlib were used to analyze the data. For backend processing in the OpenSesame GUI, PsychoPy was used.</p></li>
<li><p><strong>Eye Tracker</strong>: The experiment is conducted using the GazePoint GP3+ eye tracker. It is a binocular eye tracker that can record at 150 Hz The eye tracker is connected to the computer and the participants are seated at a distance of 60 cm from the screen. The experiment was conducted in a dimly lit laboratory setup to avoid any external light source that might interfere with the eye tracking.</p></li>
</ul>
</section>
<section id="structure-of-the-stimulus" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="structure-of-the-stimulus"><span class="header-section-number">2.2</span> Structure of the Stimulus</h2>
<p>The experiment is designed to test the participants’ ability to predict the upcoming word in a spoken instruction. The experiment is designed in such a way that the participants are presented with a visual display of four objects in a grid and they are instructed to click on the object that matches the spoken instruction.</p>
<p>A trial in the experiment means the response to one spoken instruction.</p>
<p>The following User Interface is presented to the participants:</p>
<div id="fig-ui" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/stim_grid.png" class="img-fluid figure-img" style="width:70.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2: User Interface of one trial - In each trial we have a 3x3 grid structure with four objects in it. Each trial has four stimulus displayed. The four stimulus are a combination of referent, cohort, rhyme and unrelated words. All or atleast two of the combinations are present in each trial according to the condition set (Full competitor, Rhyme competitor, Unrelated competitor etc.), which will be referred in the later part of the report. The stimulus used are only line drawings of the objects, to remove anmibuity in the visual display. The dot in the center grid is the fixation point for the participants.</figcaption>
</figure>
</div>
</section>
<section id="design-of-the-experiment" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="design-of-the-experiment"><span class="header-section-number">2.3</span> Design of the Experiment</h2>
<p>The experiment follows the following structure in OpenSesame:</p>
<ol type="1">
<li><strong>Introduction to the experiment</strong>: It contains some preliminary instructions for the participants to understand the experiment. It also mentions that each progression will require a mouse click. The foreground color of the text is set to black and the background color is set to white throughout the experiment.</li>
</ol>
<div id="fig-ui" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="img/intro_script.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;3: Introduction</figcaption>
</figure>
</div>
<ol start="2" type="1">
<li><p><strong>Initialization of variables</strong>: The position variables (Top, Buttom, Left and Right) are initialized and are used to set the position of the objects in the grid. The pygaze module is also intialized to record the eye movements of the participants.</p></li>
<li><p><strong>Trial Loop Items</strong>: This loop runs the experiment for 24 trials. The trial loop contains the following sequence of events:</p>
<ul>
<li><p><strong>Fixation Cross</strong>: A fixation cross is displayed at the center of the screen. The fixation cross is a black dot on a white background. The fixation cross is displayed to ensure that the participants are looking at the center of the screen before the spoken instruction is played. The fixation cross is displayed using the sketchpad item in OpenSesame.</p></li>
<li><p><strong>Stimulus</strong>:</p>
<ol type="1">
<li>The visual stimulus for each trial is loaded from the <code>stimuli.csv</code> file. The csv file contains information about the four objects that are displayed in the grid. The csv file contains the following information:
<ul>
<li><strong>Stimulus</strong>: The name of the objects that is displayed in the grid.</li>
<li><strong>Type</strong>: The type of the object. The type can be referent, cohort, rhyme or unrelated. The type of the object is used to determine the condition of the trial.</li>
<li><strong>Condition</strong>: The condition of the trial.</li>
<li><strong>Target</strong>: The target object that the participants have to click on. You can find the stimuli.csv file <a href="https://github.com/ReboreExplore/visual_world_paradigm_project/blob/main/stimuli/stimuli-final.csv">here</a>.</li>
</ul></li>
<li>We also have accompaning audio stimuli for each trial. The audio is digitally recorded. The audio stimuli are recorded in the following format:
<ul>
<li><strong>Instruction</strong>: ’FixateHow to run the analysisbject that the participants have to click on. You can find the audio stimuli <a href="https://github.com/ReboreExplore/visual_world_paradigm_project/blob/main/stimuli/audio-stimuli">here</a>. Each response is captured with a mouse click. The mouse click is recorded and logged using the mouse_response item in OpenSesame.</li>
</ul></li>
</ol></li>
<li><p><strong>Logging</strong>: The onset and offset of the fixation cross and the stimulus (both audio and visual) is logged for each trail. We also log the position of the mouse click and the target object along with its position (top,right, buttom, left) that the participants clicked on. (<em>More details will be proviided in the preprocessing and analysis section</em>.)</p></li>
<li><p><strong>Gaze Contingency</strong>: Two fixation audio prompts which says <em>‘Fixate at the center’</em> and ‘<em>Now fixate at the center</em>’ and marks the beginning and end of one trail.The fixation audio prompt is played to ensure that the participants are looking at the center of the screen before the spoken instruction is played. This is implemented by introducing a delay of 1.1s after the prompt. <img src="img/trial_timeline.png" id="fig-ui" class="img-fluid" style="width:90.0%" alt="Timeline of a trial"></p></li>
</ul></li>
<li><p><strong>End of Experiment</strong>: The experiment ends with a thank you message for the participants.</p></li>
</ol>
</section>
<section id="logic-of-the-experiment" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="logic-of-the-experiment"><span class="header-section-number">2.4</span> Logic of the experiment</h2>
<ol type="1">
<li><p>Stimuli are chosen as per the different pairs of sets included in the reference paper by Paul D.Allopenna, James S. Magnuson and Michael K. Tanenhaus.</p>
<ul>
<li>For e.g., One criteria of choosing those words are based on frequency per million words in the Kucera and Francis, 1967, corpus.</li>
</ul></li>
<li><p>A fixation at any point on the screen indicates that the participant is paying attention to it. Thus we record the fixations throughout the experiment to deduce the attention of the pariticipant when we instruct them to fixate or look at a certain point of the canvas.</p></li>
<li><p>Noting timestamps of the samples is essential. Our experiment is designed to record how a participants attends to the stimuli and how they respond to the spoken instruction while the instruction is unfolding. Thus we record the timestamps of the samples to understand the chronology of the fixation events.</p></li>
<li><p>Fixations at the centre of the screen marks the start and end of a trial. This is to make sure we don’t overlap the data of two trials while recording the data since each participant will have different response times and thus a fixed duration for each trial for timeout will not be feasible.</p></li>
</ol>
</section>
</section>
<section id="stimulus-design" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Stimulus Design</h1>
</section>
<section id="stimuli-preprocessing" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Stimuli Preprocessing</h1>
<p>The stimuli collected needed to be preprocessed before they could be used in the experiment. The preprocessing steps are as follows:</p>
<ol type="1">
<li><p>Resizing the line drawings into 256x256 pixels. The OpenCV library was was used to read and resize the images.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> cv2.resize(img, size)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>Converting the audio files to <code>.wav</code> format. The audio files were generated in <code>.mp3</code> format. The</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> file <span class="kw">in</span> <span class="va">$DIRPATH</span>/<span class="pp">*</span>.mp3<span class="kw">;</span> <span class="cf">do</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>        <span class="va">filename</span><span class="op">=</span><span class="va">$(</span><span class="fu">basename</span> <span class="st">"</span><span class="va">$file</span><span class="st">"</span><span class="va">)</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">filename</span><span class="op">=</span><span class="st">"</span><span class="va">${filename</span><span class="op">%</span>.<span class="pp">*</span><span class="va">}</span><span class="st">"</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="ex">ffmpeg</span> <span class="at">-i</span> <span class="va">$file</span> <span class="va">$OUTDIR</span>/<span class="va">$filename</span>.wav</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">done</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p>A trailing silence after each audio was observed which would affect the response time of the participants. The silence was removed using the <code>pydub</code> library.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> detect_leading_silence(sound, silence_threshold, chunk_size<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>        trim_ms <span class="op">=</span> <span class="dv">0</span> <span class="co"># ms</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> sound[trim_ms:trim_ms<span class="op">+</span>chunk_size].dBFS <span class="op">&lt;</span> silence_threshold:</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>            trim_ms <span class="op">+=</span> chunk_size</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> trim_ms</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The function analyzes an audio snippet to find the duration of the silence at the beginning of the signal. It iterates over chunks of the audio and measuring the volume (dBFS) in each chunk until the volume exceeds the provided silence threshold. The accumulated time of trimmed silence is then returned as the result and then removed using the <code>sound[trim_ms:]</code> function, spectifying the start and the end trim duration.</p></li>
<li><p>The sampling rate of all the audio samples was also made equal to work with the <code>PsychoPy</code> backend. The sampling rate was changed to 48Hz.</p></li>
</ol>
</section>
<section id="conditions" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Conditions</h1>
</section>
<section id="randomization-and-quality-control" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Randomization and Quality Control</h1>
</section>
<section id="experiment-organization" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Experiment Organization</h1>
</section>
<section id="preprocessing-and-analysis" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Preprocessing and Analysis</h1>
<!-- TODO: add introduction to this section -->
<section id="organizing-the-raw-data-into-trial-wise-data" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="organizing-the-raw-data-into-trial-wise-data"><span class="header-section-number">8.1</span> Organizing the raw data into trial-wise data</h2>
<p>The basic unit of analysis in the visual world paradigm experiment is a trial. A trial is a single instance of the experiment. The first task was to organize the raw data into trial-wise data. Here the raw data was present in the .tsv files. Each file contained the data for a single participant. The data was read into a pandas dataframe named <code>df_interest</code> and then the columns that were not required were dropped. The columns, <code>TIME</code>, <code>BPOGX</code>, <code>BPOGY</code>, <code>FPOGD</code>, <code>FPOGX</code>, <code>FPOGY</code>, <code>FPOGV</code> and <code>USER</code> were relevant for our analysis so these were the columns remaining in the dataframe.</p>
<!-- TODO: write about FPOGV filtering! -->
<p>In order to organize the entries of the dataframe into trials, the rows corresponding to the start and end of the trials needed to be identified. After acquiring the indices of the corresponding rows, the dataframe was split into multiple dataframes, each corresponding to a single trial.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get the indices of the rows where the user column contains the phrase 'START_TRIAL'</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>start_indices <span class="op">=</span> df_interest[df_interest[<span class="st">"USER"</span>].<span class="bu">str</span>.contains(<span class="st">"START_TRIAL"</span>)].index</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># get the indices of the rows where the user column contains the phrase 'FINAL_FIXATION_END'</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>end_indices <span class="op">=</span> df_interest[df_interest[<span class="st">"USER"</span>].<span class="bu">str</span>.contains(<span class="st">"FINAL_FIXATION_END"</span>)].index</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># split the dataframe based on the start and end indices</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>df_list <span class="op">=</span> [</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    df_interest.iloc[start_indices[i] : end_indices[i]]</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(start_indices))</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>At this point, the dataframes corresponding to the individual trials were ready. Our analysis is mainly concerned with the gaze data from the point of onset of the audio stimilus up till the point at which the participant clicks on a stimulus. So, the dataframes were further sliced to retain only the data from the specified interval. In order to perform this, the <code>USER</code> column was used. The rows corresponding to the start of the audio stimulus and the end of the click response were identified by the strings <code>LOG_AUDIO_TARGET_START</code> and <code>CLICK_RESPONSE_END</code> respectively. The rows between these two rows were sliced and the resulting dataframes were stored in a list named <code>audio_df_list</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the row index where the user column contains the phrase 'LOG_AUDIO_TARGET_START'</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>audio_start_index <span class="op">=</span> selected_df[</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    selected_df[<span class="st">"USER"</span>].<span class="bu">str</span>.contains(<span class="st">"LOG_AUDIO_TARGET_START"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>].index[<span class="dv">0</span>]</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># extract the row index where the user column contains the phrase 'LOG_AUDIO_TARGET_END'</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>audio_end_index <span class="op">=</span> selected_df[</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    selected_df[<span class="st">"USER"</span>].<span class="bu">str</span>.contains(<span class="st">"CLICK_RESPONSE_END"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>].index[<span class="dv">0</span>]</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># split the dataframe based on the audio start and end indices</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># store the split dataframe in a list</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>audio_df_list.append(selected_df.iloc[audio_start_index : audio_end_index <span class="op">+</span> <span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="extracting-trial-information" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="extracting-trial-information"><span class="header-section-number">8.2</span> Extracting trial information</h2>
<p>The logs present in the .tsv files are important for our analysis. Apart from containing the data recordings from the experiments, they also contain the information about the individual trials. In the text block below, the logs for a sample trial are shown.</p>
<pre class="text"><code>START_EXP
START_TRIAL: 0 T: SADDLE.PNG R: PICKLE.PNG B: PADLOCK.PNG L: CANDY.PNG
FIXATE_CENTER_AUDIO_ONSET, COND: 12 TARGET: CANDY
CENTRE_GAZE_START
INSTRUCTION_TO_CLICK_ONSET
LOG_AUDIO_TARGET_START
LOG_AUDIO_TARGET_END
CLICK_RESPONSE_END
FINAL_FIXATION_START, SELECTED: CANDY.PNG
FINAL_FIXATION_END
….
….
….
….
STOP_EXP</code></pre>
<p>The logs are in the form of a sequence of events. Each log event is a line in the log file. Out of these log events, the following ones are relevant for our analysis:</p>
<ul>
<li><code>START_TRIAL: 0 T: SADDLE.PNG R: PICKLE.PNG B: PADLOCK.PNG L: CANDY.PNG</code> : This line contains the information about the trial. The trial number is 0. The images on the left, right, top and bottom of the target image are <code>SADDLE.PNG</code>, <code>PICKLE.PNG</code>, <code>PADLOCK.PNG</code> and <code>CANDY.PNG</code> respectively.</li>
<li><code>FIXATE_CENTER_AUDIO_ONSET, COND: 12 TARGET: CANDY</code>: Other than indicating the onset of the audio for fixation, this line also contains the target word and the condition number. In this case, the target word is <code>CANDY</code> and the condition number is 12.</li>
<li><code>FINAL_FIXATION_START, SELECTED: CANDY.PNG</code>: This line indicates the onset of the final fixation on the target image and the stimulus that was selected. The participant selected the image <code>CANDY.PNG</code> as the target image.</li>
</ul>
<p>Following the slicing procedure mentioned the previous section, the indices of the rows corresponding to these three log events are retrieved.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get all rows whose indices are stored in start_indices</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># will be used to extract the position of the stimuli</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>trial_strings <span class="op">=</span> df_interest.iloc[start_indices][<span class="st">"USER"</span>].reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># get the indices of rows that contain the phrase 'FIXATE_CENTER_AUDIO_ONSET'</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>target_row_indices <span class="op">=</span> df_interest[</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    df_interest[<span class="st">"USER"</span>].<span class="bu">str</span>.contains(<span class="st">"FIXATE_CENTER_AUDIO_ONSET"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>].index</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>target_rows <span class="op">=</span> df_interest.iloc[target_row_indices].reset_index(drop<span class="op">=</span><span class="va">True</span>)[<span class="st">"USER"</span>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co"># get the indices of rows that contain the phrase 'FINAL_FIXATION_START'</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>fixation_row_indices <span class="op">=</span> df_interest[</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    df_interest[<span class="st">"USER"</span>].<span class="bu">str</span>.contains(<span class="st">"FINAL_FIXATION_START"</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>].index</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>fixation_rows <span class="op">=</span> df_interest.iloc[fixation_row_indices].reset_index(drop<span class="op">=</span><span class="va">True</span>)[<span class="st">"USER"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The retrieved data were all of the datatype string so regex was used to extract the data points of interest. This consisted of the name of the stimulus at the top, bottom, left and right positions of the grid, the target word, the condition number and the selected stimulus. The extracted data were stored in a python dictionary named <code>stimuli_loc_dict</code> with appropriate keys.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use regex to extract the number afer 'COND:'</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>cond_numbers <span class="op">=</span> [re.findall(<span class="vs">r"COND: (\d+)"</span>, row)[<span class="dv">0</span>] <span class="cf">for</span> row <span class="kw">in</span> target_rows]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># use regex to extract the word after 'TARGET:'</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>target_words <span class="op">=</span> [re.findall(<span class="vs">r"TARGET: (\w+)"</span>, row)[<span class="dv">0</span>] <span class="cf">for</span> row <span class="kw">in</span> target_rows]</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># use regex to extract the word after 'SELECTED: '</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>selected_words <span class="op">=</span> [re.findall(<span class="vs">r"SELECTED: (\w+)"</span>, row)[<span class="dv">0</span>] <span class="cf">for</span> row <span class="kw">in</span> fixation_rows]</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co"># use regex to extract the image names at the top, bottom, right and left positions</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>top_stimuli <span class="op">=</span> [</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    re.findall(<span class="vs">r"T: (\w+)"</span>, trial_string)[<span class="dv">0</span>] <span class="cf">for</span> trial_string <span class="kw">in</span> trial_strings</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>bottom_stimuli <span class="op">=</span> [</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    re.findall(<span class="vs">r"B: (\w+)"</span>, trial_string)[<span class="dv">0</span>] <span class="cf">for</span> trial_string <span class="kw">in</span> trial_strings</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>right_stimuli <span class="op">=</span> [</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    re.findall(<span class="vs">r"R: (\w+)"</span>, trial_string)[<span class="dv">0</span>] <span class="cf">for</span> trial_string <span class="kw">in</span> trial_strings</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>left_stimuli <span class="op">=</span> [</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    re.findall(<span class="vs">r"\sL: (\w+)"</span>, trial_string)[<span class="dv">0</span>] <span class="cf">for</span> trial_string <span class="kw">in</span> trial_strings</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The gaze data contained in <code>audio_df_list</code> provided the coordinates where the participant was fixating at a given timestamp but for our task we needed to know which stimulus the participant was fixating at. The coordinates of the grid boxes were noted from the OpenSesame experiment UI. But one issues with this data is that these coordinates had the origin at the center of the screen whereas the gaze data had the origin at the top left corner of the screen. So, the coordinates of the grid boxes were converted to the coordinate system of the gaze data and then scaled to the range [0, 1]<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. The functions <code>shift_coordinate_system</code> and <code>shift_coordinate_system_single</code> were defined for this purpose. The function <code>shift_coordinate_system</code> accepted a dictionary of coordinates while the function <code>shift_coordinate_system_single</code> accepted a single set of coordinates (tuple). The functions returned the shifted coordinates.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># shift the origin from (0, 0) to (-960, 540)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># perform the same on outer_points and inner_points</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> shift_coordinate_system(coord_dict):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> key, value <span class="kw">in</span> coord_dict.items():</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        coord_dict[key] <span class="op">=</span> (value[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">960</span>, <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> value[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">540</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># scale to [0, 1]</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        coord_dict[key] <span class="op">=</span> (coord_dict[key][<span class="dv">0</span>] <span class="op">/</span> <span class="dv">1920</span>, coord_dict[key][<span class="dv">1</span>] <span class="op">/</span> <span class="dv">1080</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coord_dict</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> shift_coordinate_system_single(coord):</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    coord <span class="op">=</span> (coord[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">960</span>, <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> coord[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">540</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    coord <span class="op">=</span> (coord[<span class="dv">0</span>] <span class="op">/</span> <span class="dv">1920</span>, coord[<span class="dv">1</span>] <span class="op">/</span> <span class="dv">1080</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coord</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>shift_coordinate_system</code> function can convert OpenSesame UI coordinates to the cartesian coordinate system (origin on the bottom left corner) and scale them to the range <code>[0, 1]</code>. The gaze data acquired from the GP3 eye tracker follows a different coordinate system. The origin of the gaze data coordinate system is at the top left corner of the screen. Additionally, the y-axis is inverted, meaning that the y-coordinate increases as the participant looks down. In order to convert the gaze data to the cartesian coordinate system in order to enable comparison with the transformed OpenSesame UI coordinates, the function <code>shift_coordinate_system_bottom_left_to_top_left</code><!-- TODO: fix incorrect name of function --> was defined. The scaled version of the cartesian coordinates was chosen in order to enable use with plotting libraries such as <em>matplotlib</em> and <em>seaborn</em>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> shift_coordinate_system_bottom_left_to_top_left(x, y):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x, <span class="op">-</span><span class="dv">1</span> <span class="op">*</span> y <span class="op">+</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note:
</div>
</div>
<div class="callout-body-container callout-body">
<p>The GP3 gaze data coordinates are in the range <code>[0, 1]</code> so no scaling is required.</p>
</div>
</div>
</section>
<section id="fixation-plots" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="fixation-plots"><span class="header-section-number">8.3</span> Fixation plots</h2>
<p>The preprocessing steps described in the previous sections are performed on the recorded data, it is possible to plot the fixations of the participants <!-- TODO: explain further in a previous section -->. Such plots allow us visualize the fixations of the participants and identify any outliers. The plot elements can be classified into two groups:</p>
<ol type="1">
<li>Overlay elements: These elements are plotted in order to provide reference for the position of the grid and indicate the stimulus image in each grid box element. The condition number and the target word are also displayed in the plot. The function <code>draw_grid</code> is used to draw the grid.</li>
</ol>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_grid(inn, out, ax):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># draw line from A to B</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    ax.plot(</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        [out[<span class="st">"A"</span>][<span class="dv">0</span>], out[<span class="st">"B"</span>][<span class="dv">0</span>]], [out[<span class="st">"A"</span>][<span class="dv">1</span>], out[<span class="st">"B"</span>][<span class="dv">1</span>]], color<span class="op">=</span><span class="st">"black"</span>, alpha<span class="op">=</span><span class="fl">0.3</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># draw line from B to C</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    ax.plot(</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        [out[<span class="st">"B"</span>][<span class="dv">0</span>], out[<span class="st">"C"</span>][<span class="dv">0</span>]], [out[<span class="st">"B"</span>][<span class="dv">1</span>], out[<span class="st">"C"</span>][<span class="dv">1</span>]], color<span class="op">=</span><span class="st">"black"</span>, alpha<span class="op">=</span><span class="fl">0.3</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># draw line from C to D</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create a tiny circle at the center</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    ax.scatter(inn[<span class="st">"M"</span>][<span class="dv">0</span>], inn[<span class="st">"M"</span>][<span class="dv">1</span>], color<span class="op">=</span><span class="st">"black"</span>, s<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The text elements are plotted using <code>matplotlib.pyplot.text()</code> function. See example:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># top stimuli</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>ax.text(</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.5</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.8685</span>,</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    stimuli_dict[i][<span class="dv">0</span>].lower(),</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    transform<span class="op">=</span>ax.transAxes,</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    fontsize<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    verticalalignment<span class="op">=</span><span class="st">"top"</span>,</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    bbox<span class="op">=</span>props,</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    ha<span class="op">=</span><span class="st">"center"</span>,</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="2" type="1">
<li>Fixation elements: These elements are plotted in order to indicate the fixations of the participants. As indicated in the code block below, the matplotlib scatter function is used.</li>
</ol>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># new_fpog_x and new_fpog_y are the x and y coordinates of the fixations</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>ax.scatter(new_fpog_x, new_fpog_y, color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note:
</div>
</div>
<div class="callout-body-container callout-body">
<p>The fixation plots can be generated by running the script <code>generate_fixation_plots.py</code> in the <code>src</code> directory. <!-- TODO: refactor this note if the location of the script is altered --></p>
</div>
</div>
</section>
<section id="deduce-location-of-fixations" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="deduce-location-of-fixations"><span class="header-section-number">8.4</span> Deduce location of fixations</h2>
<p>Using the coordinates of the edges of the grid boxes, it is possible to deduce the location of the fixations. The gridbox has four boxes that where a stimulus can be placed. The coordinates of the fixations and the coordinates of the stimulus boxes are converted to the scaled cartesian coordinate system. The function <code>check_if_within_rect</code> accepts the x and y coordinates of the fixation and the coordinates of the stimulus box and returns a boolean value indicating whether the fixation is within the stimulus box. The function <code>check_if_within_rect</code> is called for each stimulus box and the stimulus box for which the function returns <code>True</code> is the stimulus box where the participant was fixating.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_rect(x, y):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> check_if_within_rect(x, y, top_rect):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'top'</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> check_if_within_rect(x, y, right_rect):</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'right'</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> check_if_within_rect(x, y, bottom_rect):</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'bottom'</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> check_if_within_rect(x, y, left_rect):</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'left'</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> check_if_within_rect(x, y, centre_rect):</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'centre'</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'outside'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The function <code>get_rect</code> is applied to each row of the dataframe using the <code>df.apply</code> function. The resulting column is named <code>rect</code>. At the point, for each data point, we know at which stimulus box the participant was fixating.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use df.apply to apply the get_rect function to each row</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>audio_df_valid_fixation[<span class="st">"rect"</span>] <span class="op">=</span> audio_df_valid_fixation.<span class="bu">apply</span>(</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> row: get_rect(row[<span class="st">"FPOGX"</span>], row[<span class="st">"FPOGY"</span>]), axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="mapping-stimulus-location-to-stimulus-type" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="mapping-stimulus-location-to-stimulus-type"><span class="header-section-number">8.5</span> Mapping stimulus location to stimulus type</h2>
<p>The analysis plot is concerned with the stimulus type rather than the stimulus location. The fixations have already been mapped to the stimulus location so by using the data available in the csv log file it was possible to map the stimulus location to the stimulus type for each trial. The csv logfile contains the following columns, <em>referent, cohort, rhyme, distractor, target, trial number</em> and <em>condition number</em>. Each row indicates the names of the stimulus that was assigned the role of referent, cohort, rhyme, etc., for a given trial.</p>
<!-- TODO: add image here or below -->
<p>The csv log file was read into a pandas dataframe named <code>logger_df</code>. This dataframe has 36 rows, each corresponding to a trial. The information available in this dataframe can be combined with that available in the dictionary <code>stimuli_loc_dict</code> to map the stimulus location (top, right, bottom, left) to the stimulus type. The columns <code>top</code>, <code>right</code>, <code>bottom</code> and <code>left</code> were added to the dataframe <code>logger_df</code> and the values were populated using the dictionary <code>stimuli_loc_dict</code>.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># add the data from the stimuli_loc_dict to the logger_df</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">"top"</span>] <span class="op">=</span> [</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    stimuli_loc_dict[idx][<span class="dv">0</span>].lower() <span class="cf">for</span> idx <span class="kw">in</span> logger_df[<span class="st">"count_trial_sequence"</span>]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">"right"</span>] <span class="op">=</span> [</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    stimuli_loc_dict[idx][<span class="dv">1</span>].lower() <span class="cf">for</span> idx <span class="kw">in</span> logger_df[<span class="st">"count_trial_sequence"</span>]</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">"bottom"</span>] <span class="op">=</span> [</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    stimuli_loc_dict[idx][<span class="dv">2</span>].lower() <span class="cf">for</span> idx <span class="kw">in</span> logger_df[<span class="st">"count_trial_sequence"</span>]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">"left"</span>] <span class="op">=</span> [</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    stimuli_loc_dict[idx][<span class="dv">3</span>].lower() <span class="cf">for</span> idx <span class="kw">in</span> logger_df[<span class="st">"count_trial_sequence"</span>]</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>These new column were filled by the names of the stimuli but we are interested in the stimulus type. The code block below shows how the contents of the <code>logger_df</code> were utilized to fill the columns <code>top_type</code>, <code>right_type</code>, <code>bottom_type</code> and <code>left_type</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create columns 'top_type', 'right_type', 'bottom_type', 'left_type' and populate them with the type of stimuli</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># by checking if the stimuli is a referent, distractor, rhyme or cohort</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">'top_type'</span>] <span class="op">=</span> logger_df.<span class="bu">apply</span>(<span class="kw">lambda</span> row: <span class="st">'referent'</span> </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row[<span class="st">'top'</span>] <span class="op">==</span> row[<span class="st">'referent'</span>] <span class="cf">else</span> <span class="st">'distractor'</span> </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row[<span class="st">'top'</span>] <span class="op">==</span> row[<span class="st">'distractor'</span>] <span class="cf">else</span> <span class="st">'rhyme'</span> </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row[<span class="st">'top'</span>] <span class="op">==</span> row[<span class="st">'rhyme'</span>] <span class="cf">else</span> <span class="st">'cohort'</span> </span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row[<span class="st">'top'</span>] <span class="op">==</span> row[<span class="st">'cohort'</span>] <span class="cf">else</span> <span class="st">'NA'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">'left_type'</span>] <span class="op">=</span> logger_df.<span class="bu">apply</span>(<span class="kw">lambda</span> row: <span class="st">'referent'</span> </span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row[<span class="st">'left'</span>] <span class="op">==</span> row[<span class="st">'referent'</span>] <span class="cf">else</span> <span class="st">'distractor'</span> </span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row[<span class="st">'left'</span>] <span class="op">==</span> row[<span class="st">'distractor'</span>] <span class="cf">else</span> <span class="st">'rhyme'</span> </span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row[<span class="st">'left'</span>] <span class="op">==</span> row[<span class="st">'rhyme'</span>] <span class="cf">else</span> <span class="st">'cohort'</span> </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> row[<span class="st">'left'</span>] <span class="op">==</span> row[<span class="st">'cohort'</span>] <span class="cf">else</span> <span class="st">'NA'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Now every fixation could be mapped to a stimulus type i.e.&nbsp;whether the participant was fixating on the referent, distractor, rhyme or cohort. Although all required data for the mapping was available, the mapping was actually performed by the function <code>get_seen_stimuli_type</code> that loops through the rows of the <code>logger_df</code> dataframe and returns the stimulus type that the participant was fixating on. This function modified the <code>seen</code> column of the <code>audio_df_valid_fixation</code> dataframe so that it now contained the stimulus type that the participant was fixating on.</p>
</section>
<section id="issue-of-unequal-entries-per-trial" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="issue-of-unequal-entries-per-trial"><span class="header-section-number">8.6</span> Issue of unequal entries per trial</h2>
<p>The task of the final analysis plot is to visualize the proportion of fixations on the each stimulus type across trials and all participants. In order to create the plot, each trial must have equal number of data points. But the number of data points per trial is not equal, the number is dependent on the number of <strong>valid</strong> fixations made by the participant.</p>
<p>This issue is evident from the following plots:</p>
<section id="plotting-the-number-of-fixations-per-trial-for-one-participant" class="level3" data-number="8.6.1">
<h3 data-number="8.6.1" class="anchored" data-anchor-id="plotting-the-number-of-fixations-per-trial-for-one-participant"><span class="header-section-number">8.6.1</span> Plotting the number of fixations per trial for one participant</h3>
<p>This is done to visualize the number of fixations per trial for one participant. See figure below.</p>
<!-- TODO: add plot -->
<p>It is evident from the plot that the number of fixations per trial is not equal.</p>
</section>
<section id="comparing-the-trial-durations-for-each-condition-number" class="level3" data-number="8.6.2">
<h3 data-number="8.6.2" class="anchored" data-anchor-id="comparing-the-trial-durations-for-each-condition-number"><span class="header-section-number">8.6.2</span> Comparing the trial durations for each condition number</h3>
<p>The trials corresponding to each condition number posed a different task to the participant. The duration of the trials for each condition number was compared to see if the condition number had any effect on the number of fixations. See figure below.</p>
<!-- TODO: add plot -->
<p>It is evident from the plot that the duration of the trials for each condition number does not vary significantly. For the same condition number, the duration of the trials varies slightly. This is due to the fact that the participants were allowed to take their time to respond to the audio stimulus. Overall, there is no trend showing that some condition numbers have longer trials than others.</p>
</section>
<section id="solution-binning-the-data" class="level3" data-number="8.6.3">
<h3 data-number="8.6.3" class="anchored" data-anchor-id="solution-binning-the-data"><span class="header-section-number">8.6.3</span> Solution: Binning the data</h3>
<p>The data points were binned in order to ensure that each trial had equal number of data points. The binning was performed on the basis of time. An overall trial duration <code>avg_duration</code> was calculated and it was split into <code>N</code> equal parts. <code>N</code> is a user-defined parameter, it was chosen as <code>80</code> in our analysis. The data points were then binned into these parts.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>avg_duration <span class="op">=</span> <span class="fl">1.6</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Average duration is set to </span><span class="sc">{}</span><span class="st"> s"</span>.<span class="bu">format</span>(avg_duration))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># divide the avg duration into N equal parts</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">80</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>duration_thresholds <span class="op">=</span> np.linspace(<span class="dv">0</span>, avg_duration, N, endpoint<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>duration_thresholds</code> array contains the time thresholds for each bin.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note:
</div>
</div>
<div class="callout-body-container callout-body">
<p>The overall trial duration was calculated by averaging the trial duration across all trials and across all participants.</p>
</div>
</div>
<p>For determining the duration of each trial, the timestamp of the first fixation and the timestamp of the last fixation were used. The difference between these two timestamps was calculated and this was the duration of the trial. This duration was also used in the previous section to compare the trial durations for each condition number.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>first_fixation_time <span class="op">=</span> []</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>last_fixation_time <span class="op">=</span> []</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, row <span class="kw">in</span> logger_df.iterrows():</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    trial_df <span class="op">=</span> audio_df_valid_fixation[audio_df_valid_fixation[<span class="st">'trial_number'</span>] <span class="op">==</span> idx]</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    first_fixation_time.append(trial_df[<span class="st">'TIME'</span>].<span class="bu">min</span>())</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    last_fixation_time.append(trial_df[<span class="st">'TIME'</span>].<span class="bu">max</span>())</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">'first_fixation_time'</span>] <span class="op">=</span> first_fixation_time</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">'last_fixation_time'</span>] <span class="op">=</span> last_fixation_time</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>logger_df[<span class="st">'duration'</span>] <span class="op">=</span> logger_df[<span class="st">'last_fixation_time'</span>] <span class="op">-</span> logger_df[<span class="st">'first_fixation_time'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After the bin thresholds were determined, the data points were binned into these thresholds. One of the most important column of the <code>logger_df</code> dataframe was the <code>seen</code> column that contained the name of the type of stimulus that was fixated on by the participant. During binning, the <code>seen</code> column values of entries belonging to the same bin are replaced by a single value. The value is determined by the following rules: * First, the values <code>centre</code> and <code>outside</code> are replaced by <code>NA</code> (empty string). * If the bin contains no values, the seen value is set to <code>NA</code>. * If the bin contains only one value, the seen value is set to that value. * If the bin contains more than one value, the seen value is set to the value that occurs the most number of times in the bin.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note:
</div>
</div>
<div class="callout-body-container callout-body">
<p>See <code>get_relevant_rect_value()</code> function in source code for implementation details.</p>
</div>
</div>
<p>A new dataframe <code>count_df</code> was created to store the binned data. The columns of this dataframe were <code>trial_number</code>, <code>condition_number</code>, <code>start_time</code>, <code>end_time</code>, <code>bin_start</code>, <code>bin_end</code>, <code>real_val_count</code>, <code>val_count</code> and <code>seen</code>.</p>
<ul>
<li><code>trial_number</code> and <code>condition_number</code> were copied from the <code>logger_df</code> dataframe.</li>
<li><code>start_time</code> and <code>end_time</code> were the timestamps of the first and last fixation respectively belonging to the bin.</li>
<li><code>bin_start</code> and <code>bin_end</code> were the start and end time of the bin.</li>
<li><code>real_val_count</code> was the number of data points in the bin.</li>
<li><code>val_count</code> was the effective number of data points in the bin. This was the number of data points in the bin after calling the <code>get_relevant_rect_value()</code> function.</li>
<li><code>seen</code> was the value of the <code>seen</code> column after calling the <code>get_relevant_rect_value()</code> function.</li>
</ul>
</section>
</section>
<section id="implementing-the-conditions-of-competitor-sets" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="implementing-the-conditions-of-competitor-sets"><span class="header-section-number">8.7</span> Implementing the conditions of competitor sets</h2>
<p>The condition numbers of the four different types of competitor sets are as follows:</p>
<pre class="text"><code>full_competitor_sets_cond = [1, 2, 3, 4]
cohort_competitor_sets_cond = [5, 6, 7]
rhyme_competitor_sets_cond = [8, 9, 10]
distractor_competitor_sets_cond = [11, 12]</code></pre>
<p>As per the conditions, the instances of <code>rhyme</code> in the <code>seen</code> column were replaced by <code>distractor</code> for the trials with condition numbers belonging to the cohort competitor sets.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>count_df.loc[</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    count_df[<span class="st">"condition"</span>].isin(cohort_competitor_sets_cond), <span class="st">"seen"</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>] <span class="op">=</span> count_df[<span class="st">"seen"</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: <span class="st">"distractor"</span> <span class="cf">if</span> x <span class="op">==</span> <span class="st">"rhyme"</span> <span class="cf">else</span> x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Similarly, the conditions for rhyme competitor sets and distractor competitor sets were implemented.</p>
</section>
<section id="prepare-data-for-plotting" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="prepare-data-for-plotting"><span class="header-section-number">8.8</span> Prepare data for plotting</h2>
<section id="one-hot-encoding" class="level3" data-number="8.8.1">
<h3 data-number="8.8.1" class="anchored" data-anchor-id="one-hot-encoding"><span class="header-section-number">8.8.1</span> One hot encoding</h3>
<p>The calculation of fixation probabilities was made simpler by the one hot encoding of the <code>seen</code> column. This was done using the <code>pd.get_dummies()</code> function. The resulting dataframe was named <code>one_hot_count_df</code>. As a result of the one-hot encoding, the <code>seen</code> column was replaced by the columns <code>seen_cohort</code>, <code>seen_distractor</code>, <code>seen_referent</code> and <code>seen_rhyme</code>. The values of these columns were either 0 or 1. The value 1 indicated that the participant was fixating on the stimulus type indicated by the column name. The value 0 indicated that the participant was not fixating on the stimulus type indicated by the column name.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note:
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>pd.get_dummies()</code> adds columns of type <code>boolean</code>. The columns were converted to type <code>int</code> using the <code>astype()</code> function.</p>
</div>
</div>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># one hot encode the 'seen' column</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>one_hot_count_df <span class="op">=</span> pd.get_dummies(count_df, columns<span class="op">=</span>[<span class="st">'seen'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Several of the trials acted as filler trials. These trials were not relevant for our analysis so they were removed from the dataframe.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># remove the rows that are not relevant for the final analysis</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>one_hot_count_df <span class="op">=</span> one_hot_count_df[one_hot_count_df[<span class="st">'condition'</span>] <span class="op">!=</span> <span class="dv">2</span>]</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>one_hot_count_df <span class="op">=</span> one_hot_count_df[one_hot_count_df[<span class="st">'condition'</span>] <span class="op">!=</span> <span class="dv">12</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The groupby function was then used to group the rows by the columns <code>bin_start</code>, <code>bin_end</code> and calculate the fixation counts for each bin. The <code>sum()</code> function was used to calculate the fixation counts. The resulting dataframe was named <code>grouped_time_bins_df</code>.</p>
</section>
<section id="implementing-the-conditions-of-the-analysis-plot" class="level3" data-number="8.8.2">
<h3 data-number="8.8.2" class="anchored" data-anchor-id="implementing-the-conditions-of-the-analysis-plot"><span class="header-section-number">8.8.2</span> Implementing the conditions of the analysis plot</h3>
<p>The final plot consisted of lines for the referent, cohort, rhyme and distractor stimuli. As per the specification of the analysis plot, the plot for the referent stimuli was created using the fixation data from three competitor sets (full competitor set, cohort competitor set and rhyme competitor set). The plot for the cohort stimuli was created using the data only from the full competitor sets and the cohort competitor sets and the plot for the rhyme stimuli was created using data only from the full competitor sets and the rhyme competitor sets.</p>
<p>In order to implement these requirements, the dataframe <code>one_hot_count_df</code> was sliced to form three different dataframes, each corresponding to the three competitor sets. The dataframes were named <code>full_competitor_sets_df</code>, <code>cohort_competitor_sets_df</code> and <code>rhyme_competitor_sets_df</code>. The dataframe <code>full_competitor_sets_df</code> contained the data from the full competitor sets. The dataframe <code>cohort_competitor_sets_df</code> contained the data from the full competitor sets and the cohort competitor sets. The dataframe <code>rhyme_competitor_sets_df</code> contained the data from the full competitor sets and the rhyme competitor sets. The dataframes were created by filtering the rows of the <code>one_hot_count_df</code> dataframe based on the condition numbers of the competitor sets.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>full_competitor_sets_df <span class="op">=</span> one_hot_count_df[</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    one_hot_count_df[<span class="st">"condition"</span>].isin(full_competitor_sets_cond)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>...</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>rhyme_competitor_sets_df <span class="op">=</span> one_hot_count_df[</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    one_hot_count_df[<span class="st">"condition"</span>].isin(rhyme_competitor_sets_cond)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The dataframe <code>referent_calc_sets</code> was created by concatenating the dataframes <code>full_competitor_sets_df</code>, <code>cohort_competitor_sets_df</code> and <code>rhyme_competitor_sets_df</code>.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>referent_calc_sets <span class="op">=</span> pd.concat([one_hot_count_df_full_competitor_sets, one_hot_count_df_cohort_competitor_sets, </span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>one_hot_count_df_rhyme_competitor_sets], ignore_index<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Similarly, the dataframes <code>cohort_calc_sets</code> and <code>rhyme_calc_sets</code> were created.</p>
<p>The fixation counts for these dataframes were not the same as those obtained from the <code>grouped_time_bins_df</code> dataframe. This is because the data contained in the dataframes <code>referent_calc_sets</code>, <code>cohort_calc_sets</code> and <code>rhyme_calc_sets</code> were a subset of the data contained in the <code>grouped_time_bins_df</code> dataframe. While the <code>grouped_time_bins_df</code> dataframe contained the fixation counts disregarding the conditions necessary for the analysis.</p>
<p>Therefore, the groupby function for calculating the sum of the fixation counts was applied to these dataframes as well. The idea was to update these stimulus fixation counts (along with the total counts) in the <code>grouped_time_bins_df</code> dataframe.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># groupby sum for referent_calc_sets</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df_referent <span class="op">=</span> referent_calc_sets.groupby([<span class="st">'bin_start'</span>, <span class="st">'bin_end'</span>]).<span class="bu">sum</span>().reset_index()</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># groupby sum for cohort_calc_sets</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df_cohort <span class="op">=</span> cohort_calc_sets.groupby([<span class="st">'bin_start'</span>, <span class="st">'bin_end'</span>]).<span class="bu">sum</span>().reset_index()</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># groupby sum for rhyme_calc_sets</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df_rhyme <span class="op">=</span> rhyme_calc_sets.groupby([<span class="st">'bin_start'</span>, <span class="st">'bin_end'</span>]).<span class="bu">sum</span>().reset_index()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The columns of interest from these dataframes were extracted and updated in the <code>grouped_time_bins_df</code> dataframe. The columns of interest, the dataframes from which they were extracted and the columns that were updated in the <code>grouped_time_bins_df</code> dataframe are shown in the table below:</p>
<table class="table">
<colgroup>
<col style="width: 21%">
<col style="width: 37%">
<col style="width: 35%">
<col style="width: 5%">
</colgroup>
<thead>
<tr class="header">
<th>Column name<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></th>
<th>Source dataframe</th>
<th>Updated column name<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></th>
<th>Type<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>seen_referent</code></td>
<td><code>groupby_time_bins_df_referent</code></td>
<td><code>seen_referent</code></td>
<td>S</td>
</tr>
<tr class="even">
<td><code>seen_cohort</code></td>
<td><code>groupby_time_bins_df_cohort</code></td>
<td><code>seen_cohort</code></td>
<td>S</td>
</tr>
<tr class="odd">
<td><code>seen_rhyme</code></td>
<td><code>groupby_time_bins_df_rhyme</code></td>
<td><code>seen_rhyme</code></td>
<td>S</td>
</tr>
<tr class="even">
<td><code>val_count</code></td>
<td><code>groupby_time_bins_df_referent</code></td>
<td><code>referent_val_count</code></td>
<td>T</td>
</tr>
<tr class="odd">
<td><code>val_count</code></td>
<td><code>groupby_time_bins_df_cohort</code></td>
<td><code>cohort_val_count</code></td>
<td>T</td>
</tr>
<tr class="even">
<td><code>val_count</code></td>
<td><code>groupby_time_bins_df_rhyme</code></td>
<td><code>rhyme_val_count</code></td>
<td>T</td>
</tr>
</tbody>
</table>
<p>The code snippets for these changes are shown below:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># update the stimuli fixation counts</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">'seen_referant'</span>] <span class="op">=</span> groupby_time_bins_df_referant[<span class="st">'seen_referant'</span>].values</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">'seen_cohort'</span>] <span class="op">=</span> groupby_time_bins_df_cohort[<span class="st">'seen_cohort'</span>].values</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">'seen_rhyme'</span>] <span class="op">=</span> groupby_time_bins_df_rhyme[<span class="st">'seen_rhyme'</span>].values</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># update the total fixation counts</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">'referant_value_count'</span>] <span class="op">=</span> groupby_time_bins_df_referant[<span class="st">'val_count'</span>].values</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">'cohort_value_count'</span>] <span class="op">=</span> groupby_time_bins_df_cohort[<span class="st">'val_count'</span>].values</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">'rhyme_value_count'</span>] <span class="op">=</span> groupby_time_bins_df_rhyme[<span class="st">'val_count'</span>].values</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="calculating-the-fixation-probabilities" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="calculating-the-fixation-probabilities"><span class="header-section-number">8.9</span> Calculating the fixation probabilities</h2>
<p>The calculation of the fixation probabilities was the simple task of dividing the stimulus fixation counts by the respective total fixation counts. The contents of the stimulus fixation count columns were updated with the fixation probabilities.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">"seen_referant"</span>] <span class="op">=</span> groupby_time_bins_df.<span class="bu">apply</span>(</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: x[<span class="st">"seen_referant"</span>] <span class="op">/</span> x[<span class="st">"referant_value_count"</span>]</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x[<span class="st">"referant_value_count"</span>] <span class="op">!=</span> <span class="dv">0</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    axis<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">"seen_cohort"</span>] <span class="op">=</span> groupby_time_bins_df.<span class="bu">apply</span>(</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: x[<span class="st">"seen_cohort"</span>] <span class="op">/</span> x[<span class="st">"cohort_value_count"</span>]</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x[<span class="st">"cohort_value_count"</span>] <span class="op">!=</span> <span class="dv">0</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    axis<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="co"># special case for distractor competitor sets</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>val_count <span class="op">=</span> groupby_time_bins_df[<span class="st">"val_count"</span>].values</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df[<span class="st">"seen_distractor"</span>] <span class="op">=</span> groupby_time_bins_df.<span class="bu">apply</span>(</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: x[<span class="st">"seen_distractor"</span>] <span class="op">/</span> x[<span class="st">"val_count"</span>] <span class="cf">if</span> x[<span class="st">"val_count"</span>] <span class="op">!=</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    axis<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<!--- show fig -->
</section>
<section id="saving-per-participant-data" class="level2" data-number="8.10">
<h2 data-number="8.10" class="anchored" data-anchor-id="saving-per-participant-data"><span class="header-section-number">8.10</span> Saving per participant data</h2>
<p>The dataframe with the fixation probabilities were saved to a csv file. Each participant should have a separate csv file.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># save groupby_time_bins_df as 'intermediate_csv/sub-x.csv'</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>groupby_time_bins_df.to_csv(</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"intermediate_csv/sub-"</span> <span class="op">+</span> <span class="bu">str</span>(subject_number) <span class="op">+</span> <span class="st">".csv"</span>, index<span class="op">=</span><span class="va">False</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note:
</div>
</div>
<div class="callout-body-container callout-body">
<p>Before running the script for the final analysis plot, ensure that the processing script has been run for all participants. The script for the final analysis plot only considers the data that is available in the form of csv files for its analysis.</p>
</div>
</div>
</section>
<section id="plot-of-the-final-analysis" class="level2" data-number="8.11">
<h2 data-number="8.11" class="anchored" data-anchor-id="plot-of-the-final-analysis"><span class="header-section-number">8.11</span> Plot of the final analysis</h2>
<p>The main function of the final analysis plot script is to aggregate the data from the csv files and plot the fixation probabilities for each stimulus type over time.</p>
<p>The csv files were read into a pandas dataframe one by one and then concatenated into a single dataframe. The resulting dataframe was named <code>agg_df</code>.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>agg_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> csv <span class="kw">in</span> relevant_csvs:</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    filename <span class="op">=</span> <span class="st">"sub-"</span> <span class="op">+</span> <span class="bu">str</span>(csv) <span class="op">+</span> <span class="st">".csv"</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_csv(csv_path <span class="op">+</span> filename)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># concat the dataframes</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    agg_df <span class="op">=</span> pd.concat([agg_df, df], axis<span class="op">=</span><span class="dv">0</span>).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The entirety of the data is then aggregated by the columns <code>bin_start</code> and <code>bin_end</code>. The time bins are the common link between the data from different participants. The data was grouped by the time bins and the mean of the fixation probabilities is calculated for each time bin. The resulting dataframe was named <code>agg_df_mean</code>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># group_by bin_start and bin_end and get the mean of the other columns</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>agg_df_mean <span class="op">=</span> agg_df.groupby([<span class="st">'bin_start'</span>, <span class="st">'bin_end'</span>]).mean().reset_index()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The data after this step was ready for plotting.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># plot as line plots</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>ax.plot(</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    agg_df_mean[<span class="st">"bin_start"</span>], </span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    agg_df_mean[<span class="st">"seen_referant"</span>], </span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"ro--"</span>, </span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"referant"</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>ax.plot(</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    agg_df_mean[<span class="st">"bin_start"</span>], </span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>    agg_df_mean[<span class="st">"seen_cohort"</span>], </span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"bs--"</span>, </span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"cohort"</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>ax.plot(</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    agg_df_mean[<span class="st">"bin_start"</span>], </span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    agg_df_mean[<span class="st">"seen_rhyme"</span>], </span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"g^--"</span>, </span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"rhyme"</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>ax.plot(</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>    agg_df_mean[<span class="st">"bin_start"</span>], </span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>    agg_df_mean[<span class="st">"seen_distractor"</span>], </span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"c.--"</span>, </span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">"distractor"</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A vertical dashed line was drawn at the point of average audio offset. The average audio offset was calculated by averaging the audio offset for all audio stimulus.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># draw a vertical line at average_audio_stimuli_offset, do not add to legend</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>ax.vlines(</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>    average_audio_stimuli_offset, </span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span>, </span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    ymax, </span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    colors<span class="op">=</span><span class="st">'k'</span>, </span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    linestyles<span class="op">=</span><span class="st">'dashed'</span>, </span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    alpha<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># add text to the plot</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>ax.text(</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    average_audio_stimuli_offset <span class="op">+</span> <span class="fl">0.02</span>, </span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    ymax <span class="op">-</span> <span class="fl">0.05</span>, </span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Average target offset'</span>, </span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    fontsize<span class="op">=</span><span class="dv">10</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="analysis-of-the-obtained-results" class="level2" data-number="8.12">
<h2 data-number="8.12" class="anchored" data-anchor-id="analysis-of-the-obtained-results"><span class="header-section-number">8.12</span> Analysis of the obtained results</h2>
</section>
</section>
<section id="challenges-and-limitations" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Challenges and Limitations</h1>
<section id="what-we-did-not-replicate-from-the-reference-paper" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="what-we-did-not-replicate-from-the-reference-paper"><span class="header-section-number">9.1</span> What we did not replicate from the reference paper?</h2>
<ol type="1">
<li><p>Average duration of auditory stimulus was changed from 375 ms to 750 ms. It was done to as it was more comprehensible for the participants.</p>
<ul>
<li>The average duration was calculated by taking the average of the duration of all the audio stimuli which can be found <a href="https://github.com/ReboreExplore/visual_world_paradigm_project/blob/main/docs/analysis">here</a>.</li>
</ul></li>
<li><p>Number of trials for each participant was reduced from 96 to 24. It was done to reduce the time of the experiment and to avoid recalibration of the eye tracker in between the experiment.</p></li>
<li><p>Audio stimuli were digital (instead of analog). It was done to avoid any noise in the audio stimuli and also to have no influence of the experimenterś accent on the participants.</p></li>
<li><p>Participants respond with mouse clicks instead of <em>drag-and-drop to the correct box</em> function as does not support drag-and-drop functionality.</p></li>
<li><p>Use of a 3x3 grid instead of 5x5 as we didin’t require the additional boxes for the drag-and-drop functionality as in the original paper.</p></li>
<li><p>No calibration functionality after each trial was added until the participant was moving their head or eyes too much.</p></li>
</ol>
</section>
<section id="challenges" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="challenges"><span class="header-section-number">9.2</span> Challenges</h2>
<ol type="1">
<li><strong>Balancing of trials</strong>:
<ul>
<li><strong>Challenge</strong>: Our stimuli had a total of <em>23 unique` visual stimuli</em>, <em>12 different conditions</em> and <em>4 different types</em>. Adhering to proper randomization and balancing of trials was a challenge as we had to ensure that each participant saw the same number of trials for each condition and each type and such that each object appeared equal number of times.</li>
<li><strong>Solution</strong>: Although we started tith a python script to generate the trials, we had to revert to manual creation of trials as the script was not able to generate balanced trials which was a primary requirement for our experiment.</li>
</ul></li>
<li><strong>Random ‘freezes’ during experiment</strong> :
<ul>
<li><p><strong>Challenge</strong>: The experiment encountered random freezes during its run. The freezes were random and could not be reproduced. This was a major challenge as we had to restart the experiment from the beginning. The most frequent freezes was found on the <em>gaze contingency</em> check, which allowed the experiment to move forward only when the participant was looking at the center of the screen.</p></li>
<li><p><strong>Trials</strong>:</p>
<ol type="1">
<li>While True loop</li>
</ol>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    gazepos <span class="op">=</span> eyetracker.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="2" type="1">
<li>Periodic sampling</li>
</ol>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> clock.time() <span class="op">-</span> check_timer <span class="op">&gt;</span> diff:</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>            gazepos <span class="op">=</span> eyetracker.sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ol start="3" type="1">
<li><p>Switching backend to PsychoPy Made the sample rates of all the audio samples equal to work with the PsychoPy backend.</p></li>
<li><p>Number of trials Reduced the number of trials to 24 from 12 to reduce the time of the experiment but the problem still persisted.</p></li>
</ol></li>
<li><p><strong>Solution</strong>: Removal of gaze contingent features and instead introducing a delay to ensure that the participants are looking at the center of the screen before the spoken instruction is played. This was implemented by introducing a delay of 1.1s after the prompt.</p></li>
</ul></li>
<li><strong>Eye tracker calibration</strong>:
<ul>
<li><strong>Challenge</strong>: The eye tracker calibration was a challenge as the participants were not able to calibrate the eye tracker properly, due to many reasons like contact lenses, glasses, height of the participants, body posture during the experiment etc.</li>
<li><strong>Solution</strong>: THe number of participants were increased to 16 to ensure that we have atleast 12 participants with proper calibration and the timing of one full experiment was reduced to a maximum of 8 minutes to avoid recalibration in between the experiments. The participants were also given a practice trial to ensure that they are comfortable with the experiment and the eye tracker calibration.</li>
</ul></li>
</ol>
</section>
<section id="limitations" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="limitations"><span class="header-section-number">9.3</span> Limitations</h2>
<ol type="1">
<li><p>Since Visual World Paradigm is a well known experimental framework, it is possible that the participants might have been aware of the purpose of the experiment and thus might have been biased in their responses despite the large number of filler trials. Also, we used a relatively small set of pictures, which might have led to a learning effect i.e the participants might have been able to predict the target word based on the previous trials.</p></li>
<li><p>Generalizability is affected as our study participants only include university students of a specific age group, which does not fully represent the complexities and variations of real-world spoken word recognition scenarios. The results may not be applicable to other age groups or people with different educational backgrounds who might have more or less exposure to the field of cognitive psychology.</p></li>
<li><p>The study also may not fully address the universality of the observed effects across different languages as the original study as well as our replication is in English.</p></li>
</ol>
</section>
</section>
<section id="conclusion" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Conclusion</h1>
<p>In this project we attempted to investigate the dynamics of predictive language processing through the visual world paradigm. We tried to replicate the experiment conducted by Paul D. Allopenna, James S. Magnuson and Michael K. Tanenhaus in their paper and validate the hypothesis that the existence of similar sounding words leads to an increased number of fixations on them, reflecting the participants’ evolving predictions of the upcoming word. We were able to replicate the results of the original study and thus validate the hypothesis, keeping into account the limitations of our study.</p>
<p>We summarize our conclusions as follows:</p>
<ol type="1">
<li><p>The inclusion of semantically or phonetically similar words in the spoken instructions results in a higher frequency of fixations on the visual images of the words. This phenomenon illustrates how participants are continuously adjusting their predictions for the upcoming word as they engage with the content.</p></li>
<li><p>Eye movement tracking is a reliable tool for investigating the time course of spoken word recognition and capturing the mapping process while the spoken word unfolds.</p></li>
<li><p>The results and plots obtained by us provide an empirical support for continuous and incremental mapping models of word recognition and proves that word processing is not a discrete and all-or-nothing process.</p></li>
<li><p>Our results suggest that as the spoken word unfolds over time, the listener gradually narrows down the set of candidate words based on the contextual information. This competition among candidate words occurs until a single word is identified or a clear winner emerges.</p></li>
</ol>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>The scaling is performed with regard to the resolution of a screen resolution of 1920x1080. Hence, a maximum value of 1 along height and width correspond to 1080 and 1920 respectively.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>in the source dataframe<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>in <code>grouped_time_bins_df</code><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>S = stimulus fixation count, T = total fixation count<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>